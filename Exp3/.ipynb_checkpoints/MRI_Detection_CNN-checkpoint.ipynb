{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# from tensorflow.python.keras.utils import image_dataset_from_directory\n",
    "# from tensorflow.python.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 253 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dataDir = './archive/brain_tumor_dataset/'\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(dataDir, image_size= (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "2\n",
      "(32, 224, 224, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "data_iterator = dataset.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "print(len(dataset))\n",
    "print(len(batch))\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 5\n",
    "valid_size = 2\n",
    "test_size = 1\n",
    "train = dataset.take(train_size)\n",
    "valid = dataset.skip(train_size).take(valid_size)\n",
    "test = dataset.skip(train_size+valid_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.traiable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_28), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_28), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_29), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_29), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_35), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_35), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_36), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_36), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_37), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_37), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_38), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add_38), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mm:\\Third Year\\Labs\\DL LAB\\Codes\\Exp3\\MRI_Detection_CNN.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/Third%20Year/Labs/DL%20LAB/Codes/Exp3/MRI_Detection_CNN.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x \u001b[39m=\u001b[39m Dense(units\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/Third%20Year/Labs/DL%20LAB/Codes/Exp3/MRI_Detection_CNN.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m output \u001b[39m=\u001b[39m Dense(units\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/Third%20Year/Labs/DL%20LAB/Codes/Exp3/MRI_Detection_CNN.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mModel(\u001b[39minput\u001b[39;49m, output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\functional.py:159\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m--> 159\u001b[0m         [\n\u001b[0;32m    160\u001b[0m             functional_utils\u001b[39m.\u001b[39;49mis_input_keras_tensor(t)\n\u001b[0;32m    161\u001b[0m             \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\functional.py:160\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m    159\u001b[0m         [\n\u001b[1;32m--> 160\u001b[0m             functional_utils\u001b[39m.\u001b[39;49mis_input_keras_tensor(t)\n\u001b[0;32m    161\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\functional_utils.py:49\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m node_module\u001b[39m.\u001b[39mis_keras_tensor(tensor):\n\u001b[0;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[39m.\u001b[39mformat(tensor))\n\u001b[1;32m---> 49\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mnode\u001b[39m.\u001b[39mis_input\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "input = Input(shape=(224, 224, 3))\n",
    "x = Rescaling(scale= 1./127.5)(input)\n",
    "x = base_model(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=4096, activation='relu')(x)\n",
    "x = Dense(units=1000, activation='relu')(x)\n",
    "output = Dense(units=1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
